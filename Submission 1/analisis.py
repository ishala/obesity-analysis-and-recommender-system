# -*- coding: utf-8 -*-
"""analisis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hIoPebb48DvySKemeITwig_Xo-gXlY9E

# Import Library
"""

# Olah Data
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Standarisasi Data
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# K-Nearest Neighbor
from sklearn.neighbors import KNeighborsRegressor
# Random Forest
from sklearn.ensemble import RandomForestRegressor


# Evaluasi
from sklearn.metrics import mean_squared_error

"""# Data Loading"""

# path dataset obesitas
obesDfPath = 'data/ObesityDataSet_cleaned_and_data_sinthetic.csv'
obesDf = pd.read_csv(obesDfPath)

# tinjau dataset obesitas
obesDf.head()

"""# Data Assessing"""

# Cek shape dataset obesitas
obesDf.shape

"""## Penilaian Tiap Dataset"""

obesDf.info()

"""Cek data null"""

obesDf.isna().sum()

"""Cek data duplikat"""

obesDf.duplicated().sum()

"""Cek nilai statistik dataset"""

obesDf.describe()

"""Dari hasil di atas, bahwa pada dataset obesitas:
- Tidak ada nilai null
- Tidak ada nilai duplikat

Catatan:
Terdapat kesalahan tipe data ada kolom Weight, perlu perubahan dari tipe data integer menjadi float

# Data Cleaning

## Mengubah Tipe Data Kolom Weight pada Dataset Obesitas
"""

obesDf['Weight'] = obesDf.Weight.astype(float)

obesDf.head()

"""# Exploratory Data Analysis"""

obesDf.info()

"""## Deskripsi Variabel - Dataset Obesitas
1. Id: Kolom index
2. BMI (*Body Mass Index*): Indeks masa tubuh ideal (target)
3. Gender: Jenis Kelamin
4. Age: Umur
5. Height: Tinggi badan (inch)
6. Weight: Berat badan (kg)
7. family_history_with_overweight: Riwayat keluarga dengan berat badan berlebih (obesitas)
8. FAVC: Frekuensi mengkonsumsi makanan tinggi kalori
9.  FCVC: Frekuensi mengkonsumsi sayur-mayur
10. NCP: Jumlah makan pokok perhari
11. CAEC: Frekuensi makan cemilan
12. SMOKE: Kebiasaan merokok
13. CH2O: Jumlah minum air
14. SCC: Kebiasaan monitoring konsumsi kalori
15. FAF: Frekuensi kegiatan fisik
16. TUE: Waktu penggunaan perangkat (jam)
17. CALC: Frekuensi mengkonsumsi alkohol
18. MTRANS: Kategori transportasi yang digunakan
19. NObeyesdad: Kategori berat badan

Untuk uraian lebih lanjut adalah sebagai berikut:
- Terdapat 14 kolom dengan tipe data object, yaitu Id, Gender, family_history_with_overweight,FAVC,FCVC,CAEC,SMOKE,CH2O,SCC,FAF,TUE,CALC,MTRANS,NObeyesdad
- Terdapat 2 kolom dengan tipe data integer, yaitu Age dan NCP
- Terdapat 3 kolom dengan tipe data float, Height, Weight, dan BMI

## Menghapus Kolom yang Tidak Perlu
"""

# Mengambil hanya kolom yang digunakan
obesDf = obesDf[['Height', 'Weight', 'BMI', 'CAEC', 'NObeyesdad']]

obesDf.head()

"""## Pencarian Missing Value

Pada kasus dataset ini, saya hanya akan mengambil kolom yang akan digunakan pada model Machine Learning nantinya. Dengan tujuan untuk memprediksi berapa besar BMI (*Body Mass Index*) dari perhitungan tinggi badan (Height), berat badan (Weight), FAVC, dan NObeyesdad.
"""

# Cek Shape
obesDf.shape

"""## Cek Missing Value Kolom Numerik

### 1. Kolom Height
"""

heightZero = (obesDf.Height <= 0).sum()
print(heightZero)

"""### 2. Kolom Weight"""

weightZero = (obesDf.Weight <= 0).sum()
print(weightZero)

"""### 3. Kolom BMI"""

zeroBMI = (obesDf.BMI <= 0).sum()

print(zeroBMI)

"""Kesimpulan yang didapatkan adalah:

- **tidak ada *missing value*** pada kolom numerik di dataset.

## Cek Outliers
"""

obesDf.shape

"""### 1. Kolom Height"""

sns.boxplot(x=obesDf['Height'])
plt.savefig('assets/height1.png')

"""### 2. Kolom Weight"""

sns.boxplot(x=obesDf['Weight'])
plt.savefig('assets/weight1.png')

"""### 3. Kolom BMI"""

sns.boxplot(x=obesDf['BMI'])
plt.savefig('assets/BMI1.png')

"""Kesimpulan:

Terdapat data *outlier* pada :

1. Kolom Height
2. Kolom Weight

## Penanganan Outlier

Penanganan pada data-data outliers yang terdeteksi, saya menggunakan metode *Inter Quartile Range* (IQR) untuk mengeliminasinya.
"""

# Cek shape data awal
obesDf.shape

"""### Penerapan Rumus IQR"""

numerical = obesDf.select_dtypes(include=['float64', 'int64'])
categorical = obesDf.select_dtypes(include=['object'])

# Mengambil kuartil 1 dari keseluruhan data
q1 = numerical.quantile(0.25)
# Mengambil kuartil 3 dari keseluruhan data
q3 = numerical.quantile(0.75)

# Mengurangkan antara kuartil 1 dan 3
iqr = q3 - q1

# Batas atas
upper = q3 + 1.5 * iqr

# Batas bawah
bottom = q1 - 1.5 * iqr

# Rumus outliers
outliers = ((numerical < bottom) | (numerical > upper))

"""### Pengambilan Data Outliers"""

# Data outliers
dataOutliers = obesDf[outliers.any(axis=1)]

dataOutliers

"""### Menghapus Data Outliers"""

# Cek shape awal
obesDf.shape

# Menambahkan notasi not
cleanedObesDf = obesDf[~outliers.any(axis=1)]
cleanedObesDf.head()

cleanedObesDf.shape

"""## Pengecekan Outliers Lanjut

### 1. Kolom Weight
"""

sns.boxplot(x=cleanedObesDf['Weight'])
plt.savefig('assets/weight2.png')

"""### 2. Kolom Height"""

sns.boxplot(x=cleanedObesDf['Height'])
plt.savefig('assets/height2.png')

"""### 3. Kolom BMI"""

sns.boxplot(x=cleanedObesDf['BMI'])
plt.savefig('assets/BMI2.png')

"""Kesimpulan:

Dari hasil penerapan penghapusan outliers di atas, dapat dilihat bahwa masih terdeteksi outlier pada kolom *Height*. Jadi diperlukan analisis lebih lanjut yaitu mencari data tersebut agar dapat mengambil langkah yang tepat

### Mencari Data Outlier yang Tersisa

Dikarenakan tersisa hanya 1 data outlier, maka saya melakukan pengecekan data maksimal. Sebab kondisi disini data outlier berada pada urutan terakhir, yang mana itu merupakan nilai maksimum.
"""

cleanedObesDf.Height.max()

"""### Menjalankan Rumus IQR Lagi"""

numerical = cleanedObesDf.select_dtypes(include=['float64', 'int64'])
categorical = cleanedObesDf.select_dtypes(include=['object'])

# Mengambil kuartil 1 dari keseluruhan data
q1 = numerical.quantile(0.25)
# Mengambil kuartil 3 dari keseluruhan data
q3 = numerical.quantile(0.75)

# Mengurangkan antara kuartil 1 dan 3
iqr = q3 - q1

# Batas atas
upper = q3 + 1.5 * iqr

# Batas bawah
bottom = q1 - 1.5 * iqr

# Rumus outliers
outliers = ((numerical < bottom) | (numerical > upper))

"""### Memastikan Data Outlier"""

# Data outliers
dataOutliers = cleanedObesDf[outliers.any(axis=1)]

dataOutliers

"""Disini dapat dilihat bahwa kolom height yang merupakan outlier memang benar sama dengan nilai max yang sebelumnya diperiksa

### Menghapus Nilai Outlier
"""

cleanedObesDf = cleanedObesDf[~outliers.any(axis=1)]

"""### Pengecekan Outliers dengan Boxplot pada Kolom Height"""

sns.boxplot(x=cleanedObesDf['Height'])

# Cek Shape
cleanedObesDf.shape

"""Setelah melakukan beberapa langkah di atas, data sudah tidak terdapat outliers lagi dan siap untuk dilakukan analisis lebih lanjut.

## Univariate Analysis
"""

# Cek Isi Dataset
cleanedObesDf.head()

"""### Memisahkan Kategori Kolom"""

# Kolom Numerikal
numFeatures = ['Height', 'Weight', 'BMI']
# Kolom Kategorikal
catFeatures = ['CAEC', 'NObeyesdad']

"""### Olah Categorical Features

Buat Fungsi User-Defined
"""

def featuresExtract(feature):
    count = cleanedObesDf[feature].value_counts()
    percent = 100 * cleanedObesDf[feature].value_counts(normalize=True)
    df = pd.DataFrame({
        'Jumlah sampel':count,
        'Persentase':percent.round(1)
        })
    print(df)

    rot = 0
    if feature != 'CAEC':
        rot = 45
    count.plot(kind='bar', title='Jumlah Kolom ' + feature, rot=rot)

"""A. Kolom FAVC"""

feature = catFeatures[0]
featuresExtract(feature)
plt.savefig('assets/CAEC.png')

"""B. Kolom Kategori Berat Badan"""

feature = catFeatures[1]
featuresExtract(feature)
plt.savefig('assets/nobeyesdad.png')

"""### Olah Numerical Features"""

cleanedObesDf.sample(10)

cleanedObesDf.hist(bins=35, figsize=(18,15))
plt.savefig('assets/numerical.png')
plt.show()

"""Dari hasil pemetaan kolom numerik di atas, dapat disimpulkan bahwa:

1. Kolom BMI (Target)
    - Pada kolom BMI (Kolom Target) persebaran banyak data cenderung rata. Dengan perolehan banyak data terbanyak ada di kisaran BMI 27 dan 18.
    - Banyak BMI terendah ada di angka 50 dengan total hampir 0 data.
    - Kemiringan data cenderung ke kanan (Right-Skewed), tetapi masih dapat dikatakan hampir simetris.
  
2. Kolom Height
   - Data cenderung simetris.
   - Banyak data terbanyak ada di kisaran angka 1.7-1.8
  
3. Kolom Weight
   - Kemiringan data cenderung ke kanan (Right-Skewed)
   - Banyak data terbanyak ada di angka 80
   - Banyak data terendah ada di kisaran angka 140 - 160

## Multivariate Analysis

### Olah Categorical Features
"""

# Mengambil hanya kolom kategorik
catFeatures = cleanedObesDf.select_dtypes(include='object').columns.to_list()

for col in catFeatures:
    sns.catplot(x=col, y='BMI', kind='bar', dodge=False, aspect=3, data=cleanedObesDf, palette='Set3')
    plt.savefig('assets/multi-'+ col +'.png')
    plt.title('Rata-rata BMI Relatif pada Kolom ' + col)

"""Dari hasil plot multivariate di atas, dapat disimpulkan bahwa:

1. Fitur CAEC
   - Rata-rata BMI bervariasi, dengan frekuensi memakan cemilan kategori "sometimes" memiliki rata-rata tertinggi
   - Frekuensi memakan cemilan kategori "frequently" memiliki rata-rata terendah
   - Dapat diasumsikan bahwa fitur CAEC memiliki pengaruh relatif rendah terhadap fitur BMI
2. Kolom NObeyesdad
   - Rata-rata BMI bervariasi, dengan kategori "obesity_type_iii" memiliki rata-rata tertinggi
   - Kategori "insufficient_weight" memiliki rata-rata terendah
   - Dapat diasumsikan bahwa fitur NObeyesdad memiliki pengaruh relatif tinggi terhadap fitur BMi, sebab fitur ini merepresentasikan langsung data BMI yang dikonversikan dalam bentuk kategorikal

### Olah Numerical Features

Cek Korelasi dengan Pairplot
"""

sns.pairplot(cleanedObesDf, diag_kind = 'kde')
plt.savefig('assets/multi-numerical-pairplot.png')

"""Dari hasil pairplot di atas, dapat disimpulkan bahwa terdapat korelasi positif antara kolom **Weight** dan **BMI** karena terlihat terdapat pola semu menjulang ke atas secara linear. Hal ini berhubungan dengan topik dataset yang membahas representasi keadaan berat badan dengan *Body Mass index* (BMI) terhadap indikasi obesitas.

Di sisi lain, kolom tinggi badan (Height) tidak berkorelasi dengan kolom BMI. Sebab, plot yang terbentuk tidak berbentuk pola dan terkesan acak.

Selanjutnya akan dilakukan pengecekan menggunakan metode corr() dan plot menggunakan Heat Map.

Setelah itu, dapat melakukan drop columns pada kolom **CAEC** dan **NObeyesdad** karena sudah tidak digunakan lagi
"""

colsForMatrix = cleanedObesDf[['Height', 'Weight', 'BMI']]

"""Cek Korelasi Dengan Heatmap

"""

# Mengambil nilai korelasi
corrMatrix = colsForMatrix.corr().round(2)

# Menggambar Heatmap
plt.figure(figsize=(18, 8))

sns.heatmap(data=corrMatrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.savefig('assets/multi-numerical-heatmap.png')
plt.title("Matriks Korelasi untuk Fitur Numerik", size=20)

"""Dapat dilihat bahwa kolom **Weight** memiliki relasi positif kuat dengan kolom **BMI**, sebab memiliki nilai hampir mendekati +1.

Namun disini tidak dilakukan penghapusan kolom **Height**, karena akan dimasukkan ke dalam fitur untuk prediksi.

## Data Preparation
"""

# Cek isi dataframe
cleanedObesDf.head()

"""Mengencoding Fitur Kategorikal dengan One Hot Method"""

# Encoding Fitur CAEC
cleanedObesDf = pd.concat([cleanedObesDf, pd.get_dummies(cleanedObesDf['CAEC'], prefix='calories')], axis=1)
# Encoding Fitur NObeyesdad
cleanedObesDf = pd.concat([cleanedObesDf, pd.get_dummies(cleanedObesDf['NObeyesdad'], prefix='obesity')], axis=1)
# Drop fitur asli
cleanedObesDf.drop(['CAEC', 'NObeyesdad'], axis=1, inplace=True)

# Cek isi dataframe
cleanedObesDf.head()

"""Mengubah Tipe Data Menjadi Numerik"""

# Fungsi Mengubah True = 1 dan False = 0
def toInt(value):
    if type(value) == bool:
        if value == True:
            return 1
        else:
            return 0
    else:
        return value

cleanedObesDf = cleanedObesDf.applymap(toInt)

cleanedObesDf.head()

"""### Pengecekan Dimensi Dengan PCA

Mengambil fitur penentu, yaitu Height dan Weight
"""

# Memastikan relasi dengan pairplot
sns.pairplot(cleanedObesDf[['Height', 'Weight']], plot_kws={'s': 3})
plt.savefig('assets/pca.png')

"""Dari hasil analisa kedua kolom yang akan digunakan untuk prediksi, nampaknya kedua kolom **tidak memiliki korelasi**. Jadi tidak akan dilakukan reduksi dimensi.

## Train Test Split pada Data

Disini akan dilakukan pemisahan data yang akan digunakan sebagai parameter x dan y. Parameter-parameter ini nantinya yang akan digunakan utnuk dilakukan proses modelling
"""

# Mengambil parameter x
X = cleanedObesDf.drop(['BMI'], axis=1)

# Mengambil parameter y
y = cleanedObesDf['BMI']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state=42)

"""Pengecekan jumlah dan isi sample masing-masing pembagian data

a. Variabel X (keseluruhan)
"""

# Cek banyak jumlah X
print('Jumlah banyak data X adalah ', len(X))

# Cek sample isi data
X.sample(5)

"""b. Variabel X_train"""

# Cek banyak jumlah X_train
print('Jumlah banyak data X_train adalah ', len(X_train))

# Cek sample isi data
X.sample(5)

"""c. Variabel X_test"""

# Cek banyak jumlah X_test
print('Jumlah banyak data X_test adalah ', len(X_test))

# Cek sample isi data
X.sample(5)

"""## Standarisasi

Dilakukan agar data memiliki skala relatif sama atau mendekati distribusi normal. Hal ini berguna agar pemodelan dapat bekerja lebih cepat dengan performa lebih baik. Yang dilakukan standarisasi adalah pada data training saja agar tidak terjadi kebocoran data
"""

# Mengambil kolom numerik
numericalFeatures = ['Height', 'Weight']
# Mendefinisikan StandarScaler untuk standarisasi
scaler = StandardScaler()
# Melakukan penyesuaian scaller dengan data training di kolom-kolom numerik yang digunakan
scaler.fit(X_train[numericalFeatures])

# Melakukan transformasi pada data
X_train[numericalFeatures] = scaler.transform(X_train.loc[:, numericalFeatures])

# Cek isi sample
X_train[numericalFeatures].sample(20)

"""Dapat dilihat bahwa data yang ada pada kolom **Height** dan **Weight** sudah mirip. Selanjutnya adalah mencoba melihat deskripsi dari keseluruhan kolom yang telah terstandarisasi"""

X_train[numericalFeatures].describe().round(4)

"""Dapat dilihat bahwa saat ini rata-rata (mean) dan standar deviasi (std) sudah sama dari kedua kolom yang dilakukan standarisasi. Maka dapat dilanjutkan untuk proses modelling.

# Model Development

Sesuai dengan panduan pada modul, disini akan dilakukan beberapa tipe model yang akan diimplementasikan. Berikut adalah jenis-jenisnya:

1. K-Nearest Neighbor
2. Random Forest
3. Boosting Algorithm

Selanjutnya adalah mempersiapkan Dataframe untuk wadah hasil pembelajaran **fitur X** pada **X_train** proses ketiga model di atas. Wadah ini akan dijadikan pertimbangan nanti pada sesi evaluasi. Untuk metrik evaluasinya adalah *Mean Squared Error* (MSE).
"""

trainModels = pd.DataFrame(index=['trainMSE', 'testMSE'],
                columns=['KNN', 'RandomForest'])

"""### K-Nearest Neighbor

Pada algoritma ini, model akan mencari titik data dengan ukuran jarak. Untuk ukuran jarak default yang digunakan adalah **Minkowski Distance**.

"""

# Definisikan model
knnModel = KNeighborsRegressor(n_neighbors=5)

# Fitting model
knnModel.fit(X_train, y_train)

# Memasukkan hasil ke dalam wadah hasil
trainModels.loc['trainMSE', 'KNN'] = mean_squared_error(y_pred= knnModel.predict(X_train), y_true=y_train)

"""Pada parameter *n_neighbors*, nilai 5 dimaksudkan untuk mengambil 5 tetangga terdekat untuk dijadikan pertimbangan hasil prediksi

### Random Forest

Pada teknik ini, model akan dilakukan proses *bagging*, yaitu dengan memasukkan banyak variasi model dengan *hyperparameter* yang berbeda-beda. Dengan begitu, hasilnya juga akan sangat bervariasi dan independen.
"""

# Definisikan model
rfModel = RandomForestRegressor(n_estimators=10, max_depth=4, random_state=25, n_jobs=-1)

# Fitting model
rfModel.fit(X_train, y_train)

# Memasukkan hasil ke dalam wadah hasil
trainModels.loc['trainMSE', 'RandomForest'] = mean_squared_error(y_pred=rfModel.predict(X_train), y_true=y_train)

"""Penjelasan parameter-parameter di atas:
- *n_estimators* diatur sebanyak 10 untuk melakukan set pohon cabang sebanyak 10 kali.
- *max_depth* diatur sebanyak 4 agar pohon cabang hanya melakukan percabangan lagi sebanyak paling dalam 4 kali.
- *random_state* diatur sebanyak 25 agar nilai random yang dilakukan *sampling* konsisten pada kombinasi ke-25.
- *n_jobs* pada angka -1 dimaksudkan agar pekerjaan yang dilakukan oleh model dilakukan secara paralel pada keseluruhan.

### Menampilkan Hasil Training dengan Metrik MSE
"""

trainModels.loc['trainMSE', :]

"""Dari hasil di atas, maka asumsi algoritma yang dipilih untuk dijadikan solusi adalah algoritma ***K-Nearest Neighbors*** atau **KNN** sebab memiliki nilai *error* terkecil, yaitu **0.148428** pada **data training**.

# Evaluation

Setelah melakukan berbagai hal sebelumnya, maka saatnya untuk melakukan evaluasi dan uji akhir dari model yang dipilih dengan menggunakan fitur *testing*, yaitu **X_test**. Untuk metrik yang digunakan adalah *Mean Squared Error* (MSE).

## 1. Scaling Fitur X_test
"""

X_test.loc[:, numericalFeatures] = scaler.transform(X_test[numericalFeatures])

"""Setelah dilakukan proses di atas, berikut adalah *sample* hasilnya"""

X_test[numericalFeatures].sample(10)

"""## 2. Evaluasi Metrik

Evaluasi metrik perlu dilakukan pada kedua algoritma yang digunakan, yaitu KNN dan Random Forest. Sebab, penentu akhir algoritma yang terbaik adalah ketika hasil error prediksi **data testing**.

### Evaluasi KNN
"""

trainModels.loc['testMSE', 'KNN'] = mean_squared_error(y_pred=knnModel.predict(X_test), y_true=y_test)

"""### Evaluasi Random Forest"""

trainModels.loc['testMSE', 'RandomForest'] = mean_squared_error(y_pred=rfModel.predict(X_test), y_true=y_test)

"""### Tampilkan Hasil Error dengan MSE"""

trainModels

fig, ax = plt.subplots()
trainModels.plot(kind='barh', ax=ax)
plt.title('Perbandingan Error dengan MSE')
plt.savefig('assets/compare-error.png')

"""Terlihat bahwa ternyata saat dilakukan evaluasi metrik pada KNN dan Random Forest menggunakan MSE, hasil uji data testing pada **KNN** lebih kecil daripada **Random Forest** dari segi nilai *error*-nya.

## 3. Evaluasi Prediksi

### Mengambil Data Sample
"""

# Dictionary Model
modelDict = {'KNN': knnModel, 'RF': rfModel}

# Ambil Nilai X dari X_test
XForPredict = X_test[:3].copy()
# Ambil Nilai y asli dari y_test
yForPredict = {'y_true':y_test[:3]}

"""### Evaluasi Prediksi KNN dan Random Forest"""

for name, model in modelDict.items():
    yForPredict['prediksi_'+name] = model.predict(XForPredict).round(1)

pd.DataFrame(yForPredict)

"""Dari hasil di atas, dapat disimpulkan secara final bahwa algoritma **K-Nearest Neighbors** lebih unggul daripada algoritma **Random Forest** pada kasus prediksi nilai BMI di dataset obesitas ini."""